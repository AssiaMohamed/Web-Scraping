# -*- coding: utf-8 -*-
"""web scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kRCcCtq-AQLzcnrjwIpxydzIto_zOR6G
"""

import requests
from bs4 import BeautifulSoup
import json


url = "https://www.baraasallout.com/test.html"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

all_headings_h1=[]
fin = soup.find_all("h1")
for i in fin:
  all_headings_h1.append(i.get_text())
print("Extract all headings h1:",all_headings_h1)
header_h1 = ['H1 Headings:']

all_headings_h2=[]
finn = soup.find_all("h2")
for j in finn:
  all_headings_h2.append(j.get_text())
print("Extract all headings h2:",all_headings_h2)
header_h2 = ['H2 Headings:']

all_headings_p=[]
finnn = soup.find_all("p")
for a in finnn:
  all_headings_p.append(a.get_text())
print("Extract all headings p:",all_headings_p)
header_p = ['Paragraphs:']

all_headings_li=[]
finnnd = soup.find_all("li")
for b in finnnd:
  all_headings_li.append(b.get_text())
print("Extract all headings li:",all_headings_li)
header_li = ['List Items']


tables = soup.find_all("table")
table_data = []
if tables:
    rows = tables[0].find_all('tr')[1:]
    for row in rows:
        cells = row.find_all('td')
        product_name = cells[0].get_text(strip=True)
        price = cells[1].get_text(strip=True)
        stock_status = cells[2].get_text(strip=True)
        table_data.append({
                    "Product Name": product_name,
                    "Price": price,
                    "Stock Status": stock_status
                })
    print("Extracted Table Data:", table_data)
Extract_Table_Data = {
    'H1 Headings': all_headings_h1,
    'H2 Headings': all_headings_h2,
    'Paragraphs': all_headings_p,
    'List Items': all_headings_li,
    'Table data': table_data }
with open('Extract_Table_Data.json', 'w') as json_file:
    json.dump(Extract_Table_Data, json_file, indent=4)


product_cards = soup.find_all('div', class_='product-card')
products = []
for card in product_cards:
    title = card.find('h2').text.strip() if card.find('h2') else "No title"
    price = card.find('span', class_='price').text.strip() if card.find('span', class_='price') else "No price"
    stock = card.find('span', class_='stock-status').text.strip() if card.find('span', class_='stock-status') else "No stock info"
    button_text = card.find('button').text.strip() if card.find('button') else "No button text"
    product = {
        'Book Title': title,
        'Price': price,
        'Stock Availability': stock,
        'Button Text': button_text
    }
    products.append(product)
with open('Product_Information.json', 'w') as json_file:
    json.dump(products, json_file, indent=4)



forms = soup.find_all('form')
form_details = []
for form in forms:
    inputs = form.find_all('input')
    for input_field in inputs:
        field_name = input_field.get('name')
        input_type = input_field.get('type')
        default_value = input_field.get('value', '')

        form_details.append({
            'Field Name': field_name,
            'Input Type': input_type,
            'Default Value': default_value
        })
with open('Form_Details.json', 'w') as json_file:
    json.dump(form_details, json_file, indent=4)


links = []
linkk = soup.find_all('a', href=True)
for a_tag in linkk:
    link = a_tag.get('href')
    full_link = urljoin(url, link)
    links.append(full_link)

video_links = []
video = soup.find_all('iframe', src=True)
for iframe in video:
    video_links.append(iframe['src'])

image_links = []
for img in soup.find_all('img', src=True):
    image_links.append(img['src'])


all_links = {
        'Links': links,
        'Multimedia': video_links,
        'Images': image_links
    }

with open('all_links.json', 'w') as json_file:
    json.dump(all_links, json_file, indent=4)